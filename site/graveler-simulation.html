<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="preload" href="style.css" as="style"/>
    <link rel="preload" href="highlight.css" as="style"/>
    <link rol="preload" href="script.js" as="script"/>
    <script src="script.js"></script>
    <link rel="preload" href="https://fonts.gstatic.com/s/inter/v18/UcC73FwrK3iLTeHuS_fjbvMwCp504jAa1ZL7.woff2" as="font" type="font/woff2" crossorigin/>
    <link rel="preload" href="https://fonts.gstatic.com/s/electrolize/v18/cIf5Ma1dtE0zSiGSiED7AXEBuI8.woff2" as="font" type="font/woff2" crossorigin/>
    <link rel="stylesheet" href="style.css"/>
    <link rel="stylesheet" href="highlight.css"/>
    <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Barr" />
  <meta name="dcterms.date" content="2024-11-21" />
  <meta name="keywords" content="Rust, CUDA, Pokemon, Random Number
Generation" />
<title>BarrCodes - Exploding Pokemon As Fast As Possible</title>
</head>
<body>
<header class="header">
<div class="logo banneritem">
<span>B</span><span>a</span><span>r</span><span>r</span><span>C</span><span>o</span><span>d</span><span>e</span><span>s</span>
</div>
  <a class="headeritem" href="/">Home</a>
  <a class="headeritem" href="about">About Me</a>
  <button id="toggle_theme" onclick="toggle_theme()">Dark<br/>Theme</button>
</header>
<div id="content">
<h1 id="title" class="title">Exploding Pokemon As Fast As Possible</h1>
<div style="text-align: right" class="date"><em>2024-11-21</em></div>
<div class="abstract">
<p>In this post I will answer <a
href="https://www.youtube.com/@ShoddyCast">ShoddyCast</a>’s challange
and simulate Pokemon battles looking for an extremely rare sequence of
results that can save a theoretical game save from a softlock using
Rust, and later, also CUDA.</p>
</div>
<p><a href="https://github.com/CattoFace/graveler-sim">Link To The Code
On Github</a></p>
<h2 id="background">Background</h2>
<p>In Pokemon, it is sometimes possible to “softlock” the game, meaning
putting it in a state that is impossible to progress through the main
story, but the game is otherwise still functional.<br />
In some cases, the softlock is not actually impossible, but simply so
hard/long to fix, that it is significantly easier to simply reset the
game.<br />
These are the sort of scenarios the YouTube channel <a
href="https://www.youtube.com/@Pikasprey">Pikasprey Yellow</a> explores
in his videos.<br />
Today I will focus on one video in particular, <a
href="https://www.youtube.com/watch?v=GgMl4PrdQeo">Graveler’s Unlikely
Escape</a>, which has inspired <a
href="https://www.youtube.com/watch?v=M8C8dHQE2Ro">a video by
ShoddyCast</a>.<br />
I will not go into all the little details of the softlock, but the root
of the issue boils down to:</p>
<ul>
<li>The only Pokemon the player has is a single Graveler</li>
<li>This Graveler only has 2 non-damaging moves and the moves explosion
and selfdestruct, which makes the Graveler feint.</li>
<li>There is a single trainer blocking the way to the rest of the
game.</li>
<li>The only way to beat the trainer is to:
<ol type="1">
<li>Getting the Graveler paralyzed by a Paras<br />
</li>
<li>Spending the 54 non-damaging moves<br />
</li>
<li>Losing Graveler’s turn to paralysis 177 times in a row in order for
the enemy Pokemon to knock themselves out without the Graveler making
itself feint.</li>
</ol></li>
</ul>
<h3 id="the-challenge">The Challenge</h3>
<p>ShoddyCast has attempted to simulate 1 billion battles by rolling a
number between 1 and 4 231 times for each battle.<br />
His solution was written in <a
href="https://github.com/arhourigan/graveler/blob/main/graveler.py">Python</a>,
and not a very fast python solution either, so it took about 8 and a
half days to run.<br />
Understanding 8 and a half days is not an impressive amount of time, he
challenged his viewers to create a faster simulation, which is where I
come in.</p>
<h3 id="ignoring-the-real-cartridge">Ignoring The Real Cartridge</h3>
<p>Before I begin, I want to mention that simply rolling random numbers
does not mirror that actual possible results in a real game, that has
its own Pseudo-RNG algorithm, which in reality, cannot ever roll a
sequence of turns that will save the Graveler.<br />
This challenge ignores this behaviour and it’s goal is to simply roll a
number between 1 and 4, 231 times per battle, for 1 billion battles, and
return the biggest amount of lost turns.</p>
<p>Now it’s time to write some code:</p>
<h2 id="the-naive-solution---sub-10-minutes">The Naive Solution - Sub 10
Minutes</h2>
<p>Before minimizing runtime, its easy to minimize coding time, using
Rust’s iterators and the <code>rand</code> crate, a basic working
solution is:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode rust"><code class="sourceCode rust"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> roll(rng<span class="op">:</span> <span class="op">&amp;</span><span class="kw">mut</span> ThreadRng) <span class="op">-&gt;</span> <span class="dt">usize</span> <span class="op">{</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span><span class="op">..</span><span class="dv">231</span>)<span class="op">.</span>filter(<span class="op">|</span>_<span class="op">|</span> rng<span class="op">.</span>next_u32() <span class="op">%</span> <span class="dv">4</span> <span class="op">==</span> <span class="dv">0</span>)<span class="op">.</span>count()</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> main()<span class="op">{</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> <span class="kw">mut</span> rng <span class="op">=</span> <span class="pp">rand::</span>thread_rng()<span class="op">;</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">let</span> best <span class="op">=</span> (<span class="dv">0</span><span class="op">..</span><span class="dv">1_000_000_000</span>)<span class="op">.</span>map(<span class="op">|</span>_<span class="op">|</span> roll(<span class="op">&amp;</span><span class="kw">mut</span> rng))<span class="op">.</span>max()<span class="op">.</span>unwrap()<span class="op">;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="pp">println!</span>(<span class="st">&quot;{best}&quot;</span>)<span class="op">;</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Which gets me a runtime of 7-8 minutes, already orders of magnitude
faster than the ShoddyCast solution, but nowhere near as fast as it can
go, so I am not going to properly benchmark it beyond running it through
<code>time</code>.</p>
<h2 id="being-wise-with-bits---sub-1-minute">Being Wise With Bits - Sub
1 Minute</h2>
<p>Brief explanation for bitwise operations:<br />
If we have 2 <code>u8</code> numbers, let’s say 7 and 10, we can apply a
bitwise AND(<code>&amp;</code>) between them to apply the logical AND
operation to each of their bits:<br />
7 = 0b00000111<br />
&amp;<br />
10 = 0b00001010<br />
=<br />
2 = 0b00000010</p>
<p>Like other basic operators, bitwise operators are a single CPU
instruction, so they are very fast and very useful. Now how do I use
these to make the code faster?<br />
The naive roll simply generated a <code>u32</code>, and checked for the
remainder when divided by 4, usually remainder and division are slow but
for power of 2 they are optimized to bitwise operations, in this case,
<code>x % 4</code> optimizes to <code>x &amp; 3</code>, meaning “keep
only the last 2 bits”.<br />
Which means, I am rolling 32 bits, using the last 2, and throwing away
the other 30, not very efficient.</p>
<p>To utilise bitwise operations for this problem, it is useful to
notice 1 statistical property:<br />
Rolling 2 numbers between 0 and 1 twice and returning 1 if both are 0,
has the same statistical distribution as rolling a number between 0 and
3 and returning 1 if it is 0(both represent a Bernoulli trial with a
chance of 0.25).<br />
So if I had 2 random bits, I can apply AND between them, and get 0 25%
of the time, simulating a single turn.<br />
Next, if I have a pair of 231 bit numbers, I can apply AND between them,
and get the result of 231 turns at once.<br />
In reality, we don’t have 231 bit numbers(usually), we have powers of 2,
like 32, 64, and 128.<br />
<code>rand</code> can only roll <code>u32</code> and <code>u64</code>,
so for now, I will use 4 64 bit numbers for each set.<br />
That gets us 256 turns! Too many for this problem, but this is not an
issue, using another AND operation, I can simply force the last 25 bits
to always be 0.</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode rust"><code class="sourceCode rust"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">const</span> MASK<span class="op">:</span> <span class="dt">u64</span> <span class="op">=</span> <span class="op">!</span>((<span class="dv">1</span> <span class="op">&lt;&lt;</span> <span class="dv">25</span>) <span class="op">-</span> <span class="dv">1</span>)<span class="op">;</span> <span class="co">// !((1 &lt;&lt; C) - 1) is a known trick to easily get a mask that keeps the rightmost C bits</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> r1 <span class="op">=</span> rng<span class="op">.</span>next_u64() <span class="op">&amp;</span> rng<span class="op">.</span>next_u64()<span class="op">;</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> r2 <span class="op">=</span> rng<span class="op">.</span>next_u64() <span class="op">&amp;</span> rng<span class="op">.</span>next_u64()<span class="op">;</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> r3 <span class="op">=</span> rng<span class="op">.</span>next_u64() <span class="op">&amp;</span> rng<span class="op">.</span>next_u64()<span class="op">;</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">let</span> r4 <span class="op">=</span> rng<span class="op">.</span>next_u64() <span class="op">&amp;</span> rng<span class="op">.</span>next_u64() <span class="op">&amp;</span> MASK<span class="op">;</span></span></code></pre></div>
<p>Now I need to somehow count those bits, fortunately, counting the
amount of ones or zeroes in a binary number is important enough to have
its own CPU instruction, with a function that uses it in many languages,
including rust, so the roll function now looks like this:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode rust"><code class="sourceCode rust"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">const</span> MASK<span class="op">:</span> <span class="dt">u64</span> <span class="op">=</span> <span class="op">!</span>((<span class="dv">1</span> <span class="op">&lt;&lt;</span> <span class="dv">25</span>) <span class="op">-</span> <span class="dv">1</span>)<span class="op">;</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> roll(rng<span class="op">:</span> <span class="op">&amp;</span><span class="kw">mut</span> ThreadRng) <span class="op">-&gt;</span> <span class="dt">u32</span> <span class="op">{</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> r1 <span class="op">=</span> (rng<span class="op">.</span>next_u64() <span class="op">&amp;</span> rng<span class="op">.</span>next_u64())<span class="op">.</span>count_ones()<span class="op">;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> r2 <span class="op">=</span> (rng<span class="op">.</span>next_u64() <span class="op">&amp;</span> rng<span class="op">.</span>next_u64())<span class="op">.</span>count_ones()<span class="op">;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> r3 <span class="op">=</span> (rng<span class="op">.</span>next_u64() <span class="op">&amp;</span> rng<span class="op">.</span>next_u64())<span class="op">.</span>count_ones()<span class="op">;</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> r4 <span class="op">=</span> (rng<span class="op">.</span>next_u64() <span class="op">&amp;</span> rng<span class="op">.</span>next_u64() <span class="op">&amp;</span> MASK)<span class="op">.</span>count_ones()<span class="op">;</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    r1 <span class="op">+</span> r2 <span class="op">+</span> r3 <span class="op">+</span> r4</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>And the performance improvement speaks for itself: this program runs
in <strong>~40s</strong> on my laptop, over a 10x improvement from the
naive solution.</p>
<h2 id="benchmarking">Benchmarking</h2>
<p>40 seconds is still quite a while, but its just enough to start
benchmarking.<br />
I like using <a
href="https://github.com/sharkdp/hyperfine">hyperfine</a> for most of my
benchmarks, it is not as fine grained and configurable as <a
href="https://github.com/bheisler/criterion.rs">criterion</a> and <a
href="https://github.com/nvzqz/divan">divan</a>, but it is a lot simpler
to use and does what I need most of the time, kind of a supercharged
<code>time</code>.<br />
Running <code>hyperfine ./target/release/graveler</code> gives an output
that looks like this:</p>
<pre><code>Benchmark 1: target/release/graveler
  Time (mean ± σ):     40.986 s ±  1.040 s    [User: 40.572 s, System: 0.266 s]
  Range (min … max):   39.837 s … 43.665 s    10 runs</code></pre>
<p>The important part is that the current solution takes ~41 seconds to
run, this will be helpful when comparing to future solutions.<br />
Note: all but the final benchmark will be ran on my laptop, using an
i7-10750H CPU.</p>
<h2 id="free-gains---sub-10-seconds">Free Gains - Sub 10 Seconds</h2>
<p>Sometimes there are small changes that don’t change the algorithm
itself but still improve performance significantly, I’ll start by using
2 of them:</p>
<h3 id="compilation-settings">Compilation Settings</h3>
<p>The easiest gain to make is to simply apply more performance oriented
compilation settings.<br />
By default <code>--release</code> already applies a few, but it can go
further.<br />
I like adding this <a
href="https://doc.rust-lang.org/cargo/reference/profiles.html">profile</a>
to my <code>Cargo.toml</code>:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode toml"><code class="sourceCode toml"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">[profile.max]</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="dt">inherits</span> <span class="op">=</span> <span class="st">&quot;release&quot;</span> <span class="co"># start from the release defaults</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="dt">panic</span> <span class="op">=</span> <span class="st">&quot;abort&quot;</span> <span class="co"># abort on panic instead of unwind, removes unwinding codepaths</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="dt">codegen-units</span> <span class="op">=</span> <span class="dv">1</span> <span class="co"># do not split into &quot;code generation units&quot;, a little faster code at the cost of parallel codegen</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="dt">lto</span> <span class="op">=</span> <span class="cn">true</span> <span class="co"># enable &quot;Fat&quot; Link-Time-Optimization, allows optimization to work across linked source files</span></span></code></pre></div>
<p>and use the <code>RUSTFLAGS='-C target-cpu=native</code> environment
variable, which allows to compiler to target <em>my</em> CPU, instead of
a generic one that doesn’t have all the modern CPU extensions(generally,
native is not recommended when publishing code, targeting <a
href="https://en.wikipedia.org/wiki/X86-64#Microarchitecturelevels">x86-64-v1/2/3/4</a>
is better, if at all).</p>
<h3 id="faster-random-number-generation">Faster Random Number
Generation</h3>
<p>Generating random numbers can take a while, depending on the
algorithm used, every algorithm targets different things: performance,
security, statistical accuracy, etc.<br />
The goal here is performance, so I first replaced <code>rand</code> with
<code>fastrand</code>, which implements the <code>wyrand</code>
algorithm.<br />
Swapping between the crates is as simple as replacing the function calls
in-place, <code>fastrand</code> doesn’t even require us to hand over a
generated seed, it creates a thread-local one on its own(which is good
enough for us):</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode rust"><code class="sourceCode rust"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> roll() <span class="op">-&gt;</span> <span class="dt">u32</span> <span class="op">{</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> r1 <span class="op">=</span> (<span class="pp">fastrand::</span><span class="dt">u64</span>(<span class="op">..</span>) <span class="op">&amp;</span> <span class="pp">fastrand::</span><span class="dt">u64</span>(<span class="op">..</span>))<span class="op">.</span>count_ones()<span class="op">;</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> r2 <span class="op">=</span> (<span class="pp">fastrand::</span><span class="dt">u64</span>(<span class="op">..</span>) <span class="op">&amp;</span> <span class="pp">fastrand::</span><span class="dt">u64</span>(<span class="op">..</span>))<span class="op">.</span>count_ones()<span class="op">;</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> r3 <span class="op">=</span> (<span class="pp">fastrand::</span><span class="dt">u64</span>(<span class="op">..</span>) <span class="op">&amp;</span> <span class="pp">fastrand::</span><span class="dt">u64</span>(<span class="op">..</span>))<span class="op">.</span>count_ones()<span class="op">;</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> r4 <span class="op">=</span> (<span class="pp">fastrand::</span><span class="dt">u64</span>(<span class="op">..</span>) <span class="op">&amp;</span> <span class="pp">fastrand::</span><span class="dt">u64</span>(<span class="op">..</span>) <span class="op">&amp;</span> MASK)<span class="op">.</span>count_ones()<span class="op">;</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    r1 <span class="op">+</span> r2 <span class="op">+</span> r3 <span class="op">+</span> r4</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>So comparing the old solution with these changes using hyperfine, the
results are:</p>
<table>
<thead>
<tr class="header">
<th>Version</th>
<th>Average Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Original</td>
<td>40.986s</td>
</tr>
<tr class="even">
<td>fastrand</td>
<td>11.552s</td>
</tr>
<tr class="odd">
<td>profile</td>
<td>35.526s</td>
</tr>
<tr class="even">
<td>both</td>
<td>6.848s</td>
</tr>
</tbody>
</table>
<p>The random number generation took a significant amount of the time
before, and there is a massive improvement from using a faster
implementation.</p>
<h2 id="simd-is-fast">SIMD Is Fast</h2>
<p>Modern CPUs have access to SIMD(Single Instruction Multiple Data)
instructions, that can operate on multiple numbers at the same time, and
fortunately, the <code>simd_rand</code> crate has implementations for
various PRNG algorithms that utilise these instructions.<br />
For the highest performance, while ignoring minor statistical downsides,
I picked the <a href="https://prng.di.unimi.it/">xorshiro256plus</a>
algorithm.<br />
The new roll function looks like this:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode rust"><code class="sourceCode rust"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> roll(rng<span class="op">:</span> <span class="op">&amp;</span><span class="kw">mut</span> Xoshiro256PlusX4) <span class="op">-&gt;</span> <span class="dt">u32</span> <span class="op">{</span> <span class="co">// Xoshiro256PlusX4 is the state struct for this method</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> roll <span class="op">=</span> rng<span class="op">.</span>next_u64x4()<span class="op">;</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> roll2 <span class="op">=</span> rng<span class="op">.</span>next_u64x4()<span class="op">;</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> res <span class="op">=</span> roll <span class="op">&amp;</span> roll2<span class="op">;</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    res[<span class="dv">0</span>]<span class="op">.</span>count_ones() <span class="op">+</span> res[<span class="dv">1</span>]<span class="op">.</span>count_ones() <span class="op">+</span> res[<span class="dv">2</span>]<span class="op">.</span>count_ones() <span class="op">+</span> (res[<span class="dv">3</span>] <span class="op">&amp;</span> MASK)<span class="op">.</span>count_ones()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>When starting to use code that utilises SIMD, it is important to have
the required instructions available to the compiler, meaning having the
right target-cpu/target-feature set, which is another reason to only
measure the performance using the same settings as <code>both</code>
from the last section.<br />
With the new crate, <code>hyperfine</code> reports a time of
<strong>3.119s</strong>, another massive leap in performance.</p>
<h3 id="even-bigger-simds">Even Bigger SIMDs</h3>
<p><code>simd_rand</code> can generate up to a <code>u64x8</code> SIMD,
which means 512 bits per roll.<br />
Only CPUs with the AVX512 instruction set can actually perform
operations directly on such big SIMDs, but on other CPUs these
operations are simply converted to multiple smaller SIMD
instructions.<br />
My laptop does not have AVX512 so I don’t expect a very noticeable
improvement, but it will be useful when testing on a different CPU
later. Since I only need 231 bits, I can actually fit 2 rolls for every
2 sets I generate:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode rust"><code class="sourceCode rust"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> roll(rng<span class="op">:</span> <span class="op">&amp;</span><span class="kw">mut</span> Xoshiro256PlusX8) <span class="op">-&gt;</span> <span class="dt">u32</span> <span class="op">{</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> roll <span class="op">=</span> rng<span class="op">.</span>next_u64x8()<span class="op">;</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> roll2 <span class="op">=</span> rng<span class="op">.</span>next_u64x8()<span class="op">;</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">// if both bits are 1, that roll is a 1 out of 4</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> res <span class="op">=</span> roll <span class="op">&amp;</span> roll2<span class="op">;</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">// res contains 2 sets of 256 bits, split the sets and mask the 25 bits we don&#39;t want</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">u32</span><span class="pp">::</span>max(</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        res[<span class="dv">0</span>]<span class="op">.</span>count_ones()</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> res[<span class="dv">1</span>]<span class="op">.</span>count_ones()</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> res[<span class="dv">2</span>]<span class="op">.</span>count_ones()</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> (res[<span class="dv">3</span>] <span class="op">&amp;</span> MASK)<span class="op">.</span>count_ones()<span class="op">,</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        res[<span class="dv">4</span>]<span class="op">.</span>count_ones()</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> res[<span class="dv">5</span>]<span class="op">.</span>count_ones()</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> res[<span class="dv">6</span>]<span class="op">.</span>count_ones()</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> (res[<span class="dv">7</span>] <span class="op">&amp;</span> MASK)<span class="op">.</span>count_ones()<span class="op">,</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>And now I only need to call this function 500 million times, and not
1 billion times.<br />
The new time is <strong>2.886s</strong>, an appreciable improvement.</p>
<p>This is as far as I got with a single thread, now it’s time to use
next tool: <strong><em>more threads</em></strong></p>
<h2 id="more-threads---sub-1-second">More Threads - Sub 1 Second</h2>
<p>My i7-10750H has 6 cores and 12 threads, so one would imagine I can
achieve another 12x improvement, but that is not accurate.<br />
Because these calculations are 100% compute and have no memory access,
hyper-threading is expected to suffer, but 6x is still theoretically
within grasp and would be very nice to achieve.<br />
Thanks to <a href="https://docs.rs/rayon/latest/rayon/">rayon</a>,
multithreading in Rust is a breeze.<br />
In many cases all I need to do is add the crate, and turn the iterator
to a parallel one(add <code>.into_par_iter()</code> before the
<code>.map</code>).<br />
But in this case the mutable state struct <code>rng</code> poses an
issue to be solved.</p>
<h3 id="the-need-for-more-accuracy">The Need For More Accuracy</h3>
<p>Since every change so far had a big effect on performance, the setup
used until now was sufficient, but when looking for more minor
differences there are a few more things that help improve benchmark
stability:</p>
<ul>
<li>Locking the CPU to it’s base clock prevents random clock boosts from
affecting the results, this can reduce the deviation of the runs
significantly, especially when the boosts cause thermal throttling.</li>
<li>Warmup runs put the CPU in a higher power state(unless locked) and
causes the program to be cached, making the first real runs more
accurate. In some languages, it also causes code to be JIT compiled
during the warmup, making the actual runs only run the optimized version
instead of a mix that also includes the compilation time.</li>
<li>Running the program more times means more numbers to work with,
giving a more accurate average.</li>
</ul>
<p>In this case I’ve seen the standard deviation go down from 5-6% to
sometimes as low as 0.5~1%.<br />
For these reasons, all benchmarks until the final one will use 10
warm-up rounds, 50 real runs, and the CPU will be locked to it’s base
2.6GHz.<br />
For comparison, the last single-threaded version takes
<strong>4.6s</strong> under these conditions.</p>
<h3 id="the-solution">The Solution</h3>
<p>There needs to be a state for each thread separately, one option is
two use thread-local variable the functions can access:</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode rust"><code class="sourceCode rust"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="pp">thread_local!</span> <span class="op">{</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">static</span> STATE<span class="op">:</span> RefCell<span class="op">&lt;</span>Xoshiro256PlusX8<span class="op">&gt;</span> <span class="op">=</span> <span class="pp">RefCell::</span>new(<span class="op">{</span> <span class="kw">let</span> <span class="kw">mut</span> seed<span class="op">:</span> Xoshiro256PlusX8Seed <span class="op">=</span> <span class="bu">Default</span><span class="pp">::</span><span class="kw">default</span>()<span class="op">;</span> <span class="pp">rand::</span>thread_rng()<span class="op">.</span>fill_bytes(<span class="op">&amp;</span><span class="kw">mut</span> <span class="op">*</span>seed)<span class="op">;</span> <span class="pp">Xoshiro256PlusX8::</span>from_sUsually eed(seed) <span class="op">}</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> roll() <span class="op">-&gt;</span> <span class="dt">u32</span> <span class="op">{</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> roll <span class="op">=</span> STATE<span class="op">.</span>with_borrow_mut(<span class="op">|</span>state<span class="op">|</span> state<span class="op">.</span>next_u64x8())<span class="op">;</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> roll2 <span class="op">=</span> STATE<span class="op">.</span>with_borrow_mut(<span class="op">|</span>state<span class="op">|</span> state<span class="op">.</span>next_u64x8())<span class="op">;</span></span></code></pre></div>
<p>The time for this first multi-threaded solution is
<strong>985ms</strong></p>
<p>With the way <code>rayon</code> works, here there are 1 billion tasks
split into the work queues of all the threads, then when each thread
finishes a task, it gets another task from the queue, and makes sure it
wasn’t “stolen” by another thread before executing it.<br />
This is a useful model but too much for this case and adds overhead.</p>
<p>The first improvement was to only call a few functions in parallel,
as many as the threads I want to use, and have each function perform 500
million / threads iterations.</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode rust"><code class="sourceCode rust"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> thread_roll() <span class="op">-&gt;</span> <span class="dt">u8</span> <span class="op">{</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">// seeding the generator</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> <span class="kw">mut</span> seed<span class="op">:</span> Xoshiro256PlusX8Seed <span class="op">=</span> <span class="bu">Default</span><span class="pp">::</span><span class="kw">default</span>()<span class="op">;</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="pp">rand::</span>thread_rng()<span class="op">.</span>fill_bytes(<span class="op">&amp;</span><span class="kw">mut</span> <span class="op">*</span>seed)<span class="op">;</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> <span class="kw">mut</span> rng <span class="op">=</span> <span class="pp">Xoshiro256PlusX8::</span>from_seed(seed)<span class="op">;</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span><span class="op">..</span>((<span class="dv">1_000_000_000</span> <span class="op">/</span> <span class="dv">2</span>) <span class="op">/</span> <span class="pp">rayon::</span>current_num_threads()) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>map(<span class="op">|</span>_<span class="op">|</span> double_coin_roll(<span class="op">&amp;</span><span class="kw">mut</span> rng))</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>max()</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>unwrap() <span class="kw">as</span> <span class="dt">u8</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="kw">fn</span> par_roll() <span class="op">-&gt;</span> <span class="dt">u8</span> <span class="op">{</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span><span class="op">..</span><span class="pp">rayon::</span>current_num_threads())</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>into_par_iter()</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>map(<span class="op">|</span>_<span class="op">|</span> thread_roll())</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>max()</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>unwrap()</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>I added +1 to the roll count to account for truncation, in the worst
case each thread simulates 1 more battles than needed, another solution
can add 1 only to some of the threads, to get exactly 1 billion.</p>
<p>Actually, <code>rayon</code> is not even needed anymore, it can be
removed from the project completely and replaced with
<code>std::thread</code>(<code>roll</code> was modified to get the
amount to roll as a parameter):</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode rust"><code class="sourceCode rust"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> thread_count<span class="op">:</span> <span class="dt">u32</span> <span class="op">=</span> <span class="pp">thread::</span>available_parallelism()<span class="op">.</span>unwrap()<span class="op">.</span>get() <span class="kw">as</span> <span class="dt">u32</span><span class="op">;</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> per_thread<span class="op">:</span> <span class="dt">u32</span> <span class="op">=</span> <span class="dv">500_000_000</span> <span class="op">/</span> thread_count <span class="op">+</span> <span class="dv">1</span><span class="op">;</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> threads<span class="op">:</span> <span class="dt">Vec</span><span class="op">&lt;</span><span class="pp">thread::</span>JoinHandle<span class="op">&lt;</span><span class="dt">u8</span><span class="op">&gt;&gt;</span> <span class="op">=</span> (<span class="dv">1</span><span class="op">..</span>thread_count)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>map(<span class="op">|</span>_<span class="op">|</span> <span class="pp">thread::</span>spawn(<span class="kw">move</span> <span class="op">||</span> thread_roll(per_thread)))</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>collect()<span class="op">;</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">let</span> local_result <span class="op">=</span> thread_roll(per_thread)<span class="op">;</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    threads</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>into_iter()</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>map(<span class="op">|</span>t<span class="op">|</span> t<span class="op">.</span>join()<span class="op">.</span>unwrap())</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>max()</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>unwrap_or(<span class="dv">0</span>) <span class="co">// for the single thread case</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        <span class="op">.</span>max(local_result)</span></code></pre></div>
<p><code>local_result</code> makes use of the main thread instead of
spawning one more and waiting for the rest to finish.<br />
In this case I am not concerned about the order the threads finish
because they are all expected to take the same time. To find the ideal
number of threads, I ran it with different amounts of threads.</p>
<table>
<thead>
<tr class="header">
<th>Thread Count</th>
<th>Time</th>
<th>Speedup compared to 1</th>
<th>Speedup / threads</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>4.575s</td>
<td>1x</td>
<td>1</td>
</tr>
<tr class="even">
<td>2</td>
<td>2.293s</td>
<td>1.995x</td>
<td>0.9976</td>
</tr>
<tr class="odd">
<td>4</td>
<td>1.173s</td>
<td>3.9x</td>
<td>0.975</td>
</tr>
<tr class="even">
<td>6</td>
<td>866.6ms</td>
<td>5.279x</td>
<td>0.8799</td>
</tr>
<tr class="odd">
<td>8</td>
<td>904.8ms</td>
<td>5.056x</td>
<td>0.632</td>
</tr>
<tr class="even">
<td>10</td>
<td>880.1ms</td>
<td>5.198x</td>
<td>0.5198</td>
</tr>
<tr class="odd">
<td>12</td>
<td>815.4ms</td>
<td>5.611x</td>
<td>0.4676</td>
</tr>
</tbody>
</table>
<p>The <code>Speedup / threads</code> column helps measure at what point
does tan algorithm stop scaling as well. From these results, it looks
like going for more than 6 threads hardly helps, and sometimes even
hurts the performance. Even with 6 threads the scaling was not as good
as expected, only 5.279x and not 6x.</p>
<h2 id="the-end-of-the-line-for-cpu">The End Of The Line For CPU</h2>
<p>Running the 1/half threads/all threads version with no clock locking
on both my laptop, and a borrowed Ryzen 9 7950X3D(16 cores 32 threads),
here are the final results for this solution:</p>
<table>
<colgroup>
<col style="width: 45%" />
<col style="width: 19%" />
<col style="width: 18%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="header">
<th>CPU</th>
<th>Single Thread</th>
<th>Half Threads</th>
<th>All Threads</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>i7-10750H 6 Cores 12 Threads</td>
<td>2.78s</td>
<td>512ms</td>
<td>531ms</td>
</tr>
<tr class="even">
<td>Ryzen 7950X3D 16 Cores 32 Threads</td>
<td>1.78s</td>
<td>134ms</td>
<td>117ms</td>
</tr>
</tbody>
</table>
<p>But this is not the end of the challenge just yet, while I could not
go faster on a CPU, I can go a lot faster on a device built for
massively parallel computation: a GPU.</p>
<h2 id="enter-the-gpu---sub-100-milliseconds">Enter The GPU - Sub 100
Milliseconds</h2>
<h3 id="cuda-101">CUDA 101</h3>
<p>Sorry Rust, your GPU game is not quite there yet.<br />
My laptop is equipped with an Nvidia RTX 2070 Max-Q GPU, not
particularly strong, but it will get the work done for now.<br />
Computationally heavy GPU code is often written in CUDA, a C++ like
language that is compiled for Nvidia GPUs specifically as “kernel”s, and
those kernels are usually called from normal C/C++ code. In CUDA, each
kernel runs in a grid, each made out of blocks.<br />
Kernel code looks like a normal function, but it is ran at the same time
by all the thread.</p>
<h3 id="boilerplate">Boilerplate</h3>
<p>Setting up CUDA and the various variables needed to use it has a lot
of boilerplate:</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#define BLOCKSIZE </span><span class="dv">1024</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main<span class="op">()</span> <span class="op">{</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> <span class="op">*</span>d_grid_max<span class="op">;</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> deviceId<span class="op">;</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  cudaDeviceProp prop<span class="op">;</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">cudaEvent_t</span> start<span class="op">,</span> stop<span class="op">;</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  cudaEventCreate<span class="op">(&amp;</span>start<span class="op">);</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  cudaEventCreate<span class="op">(&amp;</span>stop<span class="op">);</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>  cudaEventRecord<span class="op">(</span>start<span class="op">);</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  cudaGetDevice<span class="op">(&amp;</span>deviceId<span class="op">);</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  cudaGetDeviceProperties<span class="op">(&amp;</span>prop<span class="op">,</span> deviceId<span class="op">);</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> sm_count <span class="op">=</span> prop<span class="op">.</span>multiProcessorCount<span class="op">;</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> block_per_sm <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  cudaOccupancyMaxActiveBlocksPerMultiprocessor<span class="op">(&amp;</span>block_per_sm<span class="op">,</span> rng<span class="op">,</span> BLOCKSIZE<span class="op">,</span> <span class="dv">0</span><span class="op">);</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> block_count <span class="op">=</span> sm_count <span class="op">*</span> block_per_sm<span class="op">;</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  cudaMallocManaged<span class="op">(&amp;</span>d_grid_max<span class="op">,</span> block_count<span class="op">*</span><span class="kw">sizeof</span><span class="op">(</span><span class="dt">int</span><span class="op">));</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  rng<span class="op">&lt;&lt;&lt;</span>block_count<span class="op">,</span> BLOCKSIZE<span class="op">&gt;&gt;&gt;(</span>d_grid_max<span class="op">,</span> <span class="dv">42</span><span class="op">);</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>  cudaDeviceSynchronize<span class="op">();</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>  <span class="dt">float</span> t <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> global_max <span class="op">=</span> d_grid_max<span class="op">[</span><span class="dv">0</span><span class="op">];</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">1</span><span class="op">;</span> i <span class="op">&lt;</span> block_count<span class="op">;</span> i<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    global_max <span class="op">=</span> max<span class="op">(</span>global_max<span class="op">,</span> d_grid_max<span class="op">[</span>i<span class="op">]);</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>  cudaEventRecord<span class="op">(</span>stop<span class="op">);</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>  cudaEventSynchronize<span class="op">(</span>stop<span class="op">);</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>  <span class="bu">std::</span>cout <span class="op">&lt;&lt;</span> <span class="st">&quot;Max: &quot;</span> <span class="op">&lt;&lt;</span> global_max <span class="op">&lt;&lt;</span> <span class="ch">&#39;</span><span class="sc">\n</span><span class="ch">&#39;</span><span class="op">;</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>  cudaEventElapsedTime<span class="op">(&amp;</span>t<span class="op">,</span> start<span class="op">,</span> stop<span class="op">);</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>  <span class="bu">std::</span>cout <span class="op">&lt;&lt;</span> <span class="st">&quot;kernel ran in &quot;</span> <span class="op">&lt;&lt;</span> t <span class="op">&lt;&lt;</span> <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span><span class="op">;</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>  cudaFree<span class="op">(</span>d_grid_max<span class="op">);</span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>This code will run on the CPU, and call the kernel on the GPU. The
important things to note in this function are that I am creating an
array <code>d_grid_max</code> that will hold the max value found in each
block that runs, and after the kernel finishes running, I pick the max
from that array on the CPU.<br />
The kernel is expected to simulate the 1 billion battles, split across
all the threads, and write into each entry in <code>d_grid_max</code>
the maximum value generated in each block.<br />
The <code>42</code> passed into the kernel is simply a seed to start the
PRNG inside the kernel.<br />
Now it’s time to write the code that will actually run on the GPU.</p>
<h3 id="the-kernel">The Kernel</h3>
<p>I first tried writing <code>xorshiro256plus</code> in CUDA and using
a state for each thread, but it turns out the built-in and simple
<code>curand</code> is a lot faster, so I will not show the
<code>xorshiro256plus</code> code.<br />
The first step in a kernel is usually self-identification:<br />
Each thread has local variables for the block ID within all the blocks
running the kernel, the thread ID within all the threads in the same
block, and the size of the block.<br />
Both of these are 3 dimensional, meaning one can set x,y, and z
dimensions. But this is not useful in this case.<br />
So I start the kernel by having the thread figure out it’s index:</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="dt">unsigned</span> <span class="dt">int</span> index <span class="op">=</span> threadIdx<span class="op">.</span>x <span class="op">+</span> blockIdx<span class="op">.</span>x <span class="op">*</span> blockDim<span class="op">.</span>x<span class="op">;</span></span></code></pre></div>
<p>Next is a little more setup, notably, an array shared within the
block to save the per-thread max(normal variables are thread-local):</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>  __shared__ <span class="dt">unsigned</span> <span class="dt">char</span> max_block_arr<span class="op">[</span>BLOCKSIZE<span class="op">];</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  curandState state<span class="op">;</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  curand_init<span class="op">(</span>seed <span class="op">+</span> index<span class="op">,</span> <span class="dv">0</span><span class="op">,</span> <span class="dv">0</span><span class="op">,</span> <span class="op">&amp;</span>state<span class="op">);</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">long</span> runs <span class="op">=</span> <span class="dv">1000000000</span><span class="bu">UL</span> <span class="op">/</span> <span class="op">(</span>blockDim<span class="op">.</span>x <span class="op">*</span> gridDim<span class="op">.</span>x<span class="op">)</span> <span class="op">+</span> <span class="dv">1</span><span class="op">;</span> <span class="co">// +1 to make up for truncation</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> <span class="dt">max_t</span> <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span></code></pre></div>
<p>Next is the actual simulation loop, <code>curand</code> generates 32
bit integers, so the code is a little different:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;=</span> runs<span class="op">;</span> i<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> count <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    count <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span>        <span class="co">// 32</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    count <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span>        <span class="co">// 64</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    count <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span>        <span class="co">// 96</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    count <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span>        <span class="co">// 128</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    count <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span>        <span class="co">// 160</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    count <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span>        <span class="co">// 192</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    count <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span>        <span class="co">// 224</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    count <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> MASK<span class="op">);</span> <span class="co">// 231</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="dt">max_t</span> <span class="op">=</span> max<span class="op">(</span><span class="dt">max_t</span><span class="op">,</span> count<span class="op">);</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  max_thread_arr<span class="op">[</span>threadIdx<span class="op">.</span>x<span class="op">]</span> <span class="op">=</span> <span class="dt">max_t</span><span class="op">;</span></span></code></pre></div>
<p>(<code>__popc</code> is the CUDA equivalent of
<code>count_ones</code>)<br />
And finally, 1 thread within the block will pick the maximum for the
block(I will improve this later):</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>__syncthreads<span class="op">();</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="op">(</span>threadIdx<span class="op">.</span>x <span class="op">==</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">1</span><span class="op">;</span> i <span class="op">&lt;=</span> BLOCKSIZE<span class="op">;</span> i<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>      <span class="dt">max_t</span> <span class="op">=</span> max<span class="op">(</span><span class="dt">max_t</span><span class="op">,</span> max_thread_arr<span class="op">[</span>i<span class="op">]);</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  max_block_arr<span class="op">[</span>blockIdx<span class="op">.</span>x<span class="op">]</span> <span class="op">=</span> <span class="dt">max_t</span><span class="op">;</span></span></code></pre></div>
<p><code>__syncthreads</code> is required to ensure that all the threads
finished writing their own max into <code>max_thread_arr</code>. And
that’s the entire kernel, the CPU will wait for it to
finish(<code>cudaDeviceSynchronize()</code>) and continue to find the
max from <code>max_block_arr</code>.</p>
<p>CUDA benchmarking is a little more complicated than CPU
benchmarking:</p>
<ul>
<li>There is a measurable, and in this case, significant, set up time
when starting a CUDA program.</li>
<li>CUDA is more sensitive to warm-up than the code I ran earlier.</li>
</ul>
<p>For those reasons, I will mostly benchmark the code using CUDA
specific timing, already visible in the boilerplate from earlier, but in
my benchmark I added 50 warmup runs and 1000 real runs inside the main
function.</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>  <span class="co">// warm-up</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> <span class="dv">50</span><span class="op">;</span> i<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    rng<span class="op">&lt;&lt;&lt;</span>block_count<span class="op">,</span> BLOCKSIZE<span class="op">&gt;&gt;&gt;(</span>d_grid_max<span class="op">,</span> time<span class="op">(</span><span class="kw">nullptr</span><span class="op">));</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    cudaDeviceSynchronize<span class="op">();</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    global_max <span class="op">=</span> d_grid_max<span class="op">[</span><span class="dv">0</span><span class="op">];</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">1</span><span class="op">;</span> i <span class="op">&lt;</span> block_count<span class="op">;</span> i<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>      global_max <span class="op">=</span> max<span class="op">(</span>global_max<span class="op">,</span> d_grid_max<span class="op">[</span>i<span class="op">]);</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    black_box <span class="op">+=</span> global_max<span class="op">;</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>  cudaEventRecord<span class="op">(</span>start<span class="op">);</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> i <span class="op">&lt;</span> <span class="dv">1000</span><span class="op">;</span> i<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    rng<span class="op">&lt;&lt;&lt;</span>block_count<span class="op">,</span> BLOCKSIZE<span class="op">&gt;&gt;&gt;(</span>d_grid_max<span class="op">,</span> time<span class="op">(</span><span class="kw">nullptr</span><span class="op">));</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    cudaDeviceSynchronize<span class="op">();</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    global_max <span class="op">=</span> d_grid_max<span class="op">[</span><span class="dv">0</span><span class="op">];</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> <span class="dv">1</span><span class="op">;</span> i <span class="op">&lt;</span> block_count<span class="op">;</span> i<span class="op">++)</span> <span class="op">{</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>      global_max <span class="op">=</span> max<span class="op">(</span>global_max<span class="op">,</span> d_grid_max<span class="op">[</span>i<span class="op">]);</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    black_box <span class="op">+=</span> global_max<span class="op">;</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>  cudaEventRecord<span class="op">(</span>stop<span class="op">);</span></span></code></pre></div>
<p>black_box is printed later, it is simply there to make sure compiler
optimizations don’t remove the entire loop.</p>
<p>And the results are an average of <strong>33.07ms</strong> per kernel
run.</p>
<h3 id="kernel-improvements">Kernel Improvements</h3>
<p>There are a couple optimizations I applied to the kernel:</p>
<h4 id="less-rolls-means-less-work">Less Rolls Means Less Work</h4>
<p>Because I am working with 32 bit integers, I implemented a new little
trick that was not viable with bigger sized integers:<br />
7 pairs of rolls give 448 bits, that combine to 224 turns, meaning I
need 7 more turns, made out of 14 bits.<br />
1 more roll is 32 bits, enough to fill the missing bits for 2
simulations.<br />
This means that with 29 integer rolls, 2 simulations can be
generated(instead of the previous 32 rolls).<br />
It’s not a huge difference, at best I’ll get a ~10% improvement(~10%
less rolls). So now the loop body looks like this(also reduced the loop
count to 500 million):</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> count1 <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    count1 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 32</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    count1 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 64</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    count1 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 96</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    count1 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 128</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    count1 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 160</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    count1 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 192</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    count1 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 224</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> count2 <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    count2 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 32</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    count2 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 64</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    count2 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 96</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    count2 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 128</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    count2 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 160</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    count2 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 192</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    count2 <span class="op">+=</span> __popc<span class="op">(</span>curand<span class="op">(&amp;</span>state<span class="op">)</span> <span class="op">&amp;</span> curand<span class="op">(&amp;</span>state<span class="op">));</span> <span class="co">// 224</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    <span class="dt">unsigned</span> <span class="dt">int</span> final_set <span class="op">=</span> curand<span class="op">(&amp;</span>state<span class="op">);</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    count1 <span class="op">+=</span> __popc<span class="op">(</span>final_set <span class="op">&amp;</span> final_set <span class="op">&lt;&lt;</span> <span class="dv">7</span> <span class="op">&amp;</span> MASK<span class="op">);</span>        <span class="co">// 231</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    count2 <span class="op">+=</span> __popc<span class="op">(</span>final_set <span class="op">&lt;&lt;</span> <span class="dv">14</span> <span class="op">&amp;</span> final_set <span class="op">&lt;&lt;</span> <span class="dv">21</span> <span class="op">&amp;</span> MASK<span class="op">);</span> <span class="co">// 231</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="dt">max_t</span> <span class="op">=</span> max<span class="op">(</span><span class="dt">max_t</span><span class="op">,</span> max<span class="op">(</span>count1<span class="op">,</span> count2<span class="op">));</span></span></code></pre></div>
<p>This optimization reduces the time to <strong>31.85ms</strong>, only
4% lower than before, a small but measurable improvement.</p>
<h4 id="warp-level-reduction">Warp-Level Reduction</h4>
<p>The current solution puts all the work if summarizing the block on
one thread, while the others are doing nothing, Warp-Level Reduction is
a method that uses “Warp-Level” primitives to make use of all the blocks
in the thread. I will make use of one very useful primitive:
<code>__shfl_down_sync</code>(I’m just going to call it
“shuffle”).<br />
This shuffle primitive fetches a local variable from another thread
inside the same warp, the specific thread is chosen using an offset:</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>  __syncwarp<span class="op">();</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">// intra-warp reduction</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">max_t</span> <span class="op">=</span> max<span class="op">(</span><span class="dt">max_t</span><span class="op">,</span> __shfl_down_sync<span class="op">(</span><span class="bn">0xFFFFFFFF</span><span class="op">,</span> <span class="dt">max_t</span><span class="op">,</span> <span class="dv">16</span><span class="op">));</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">max_t</span> <span class="op">=</span> max<span class="op">(</span><span class="dt">max_t</span><span class="op">,</span> __shfl_down_sync<span class="op">(</span><span class="bn">0xFFFFFFFF</span><span class="op">,</span> <span class="dt">max_t</span><span class="op">,</span> <span class="dv">8</span><span class="op">));</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">max_t</span> <span class="op">=</span> max<span class="op">(</span><span class="dt">max_t</span><span class="op">,</span> __shfl_down_sync<span class="op">(</span><span class="bn">0xFFFFFFFF</span><span class="op">,</span> <span class="dt">max_t</span><span class="op">,</span> <span class="dv">4</span><span class="op">));</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">max_t</span> <span class="op">=</span> max<span class="op">(</span><span class="dt">max_t</span><span class="op">,</span> __shfl_down_sync<span class="op">(</span><span class="bn">0xFFFFFFFF</span><span class="op">,</span> <span class="dt">max_t</span><span class="op">,</span> <span class="dv">2</span><span class="op">));</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">max_t</span> <span class="op">=</span> max<span class="op">(</span><span class="dt">max_t</span><span class="op">,</span> __shfl_down_sync<span class="op">(</span><span class="bn">0xFFFFFFFF</span><span class="op">,</span> <span class="dt">max_t</span><span class="op">,</span> <span class="dv">1</span><span class="op">));</span></span></code></pre></div>
<p><code>__syncwarp</code> is the same as <code>__syncthreads</code> but
only needs to sync threads within the same warp. A warp is a group of 32
threads that start execution together, but more importantly, allow us to
easily move variables between them.<br />
Lets break down one of these calls:
<code>__shfl_down_sync(0xFFFFFFFF, max_t,16)</code><br />
<code>0xFFFFFFFF</code> means all the threads within the warp will
participate in the shuffle.<br />
<code>max_t</code> means the <code>max_t</code> variable will be
transferred.<br />
<code>16</code> means each thread will get the variable from the thread
16 places after it. If an offset puts it outside the 32 threads, the
retrieved value is undefined, but it doesn’t matter for the use cases of
this primitive.<br />
After the first line, the first thread contains the max between it and
thread #17, thread 2 contains the max between it and thread #18 and so
on until thread #16, the contents of thread #17 are undefined.<br />
The next line does the same, but combined threads 1-16 into threads
1-8.<br />
This continues until the max of the entire warp is in thread 1.<br />
There is a useful image from NVIDIA that shows this process:<br />
<img
src="https://developer-blogs.nvidia.com/wp-content/uploads/2018/01/reduce_shfl_down-625x275.png"
alt="warp-reduction" /><br />
But this only summarizes each warp, next I need to summarizes all the
warps together:<br />
First I need to put the result of each warp in shared memory, but now
the shared memory can be made smaller:</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>  <span class="dt">unsigned</span> <span class="dt">int</span> warpIdx <span class="op">=</span> threadIdx<span class="op">.</span>x <span class="op">/</span> WARPSIZE<span class="op">;</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">unsigned</span> <span class="dt">int</span> index_in_warp <span class="op">=</span> threadIdx<span class="op">.</span>x <span class="op">%</span> WARPSIZE<span class="op">;</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  __shared__ <span class="dt">unsigned</span> <span class="dt">char</span> max_warp_arr<span class="op">[</span>WARPSIZE<span class="op">];</span> <span class="co">// replaces max_block_arr</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  <span class="op">...</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="op">&lt;</span>Warp<span class="op">-</span>Level Reduction<span class="op">&gt;</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="op">(</span>index_in_warp <span class="op">==</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    max_warp_arr<span class="op">[</span>warpIdx<span class="op">]</span> <span class="op">=</span> <span class="dt">max_t</span><span class="op">;</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span></code></pre></div>
<p>And finally, I used another Warp-Level Reduction within the first
warp to find the max within the entire block:</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>  __syncthreads<span class="op">();</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="op">(</span>warpIdx <span class="op">==</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span> <span class="co">// reduce all other warps in the block to one value</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">unsigned</span> <span class="dt">char</span> max_block <span class="op">=</span> max_warp_arr<span class="op">[</span>index_in_warp<span class="op">];</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    max_block <span class="op">=</span> max<span class="op">(</span>max_block<span class="op">,</span> __shfl_down_sync<span class="op">(</span><span class="bn">0xFFFFFFFF</span><span class="op">,</span> max_block<span class="op">,</span> <span class="dv">16</span><span class="op">));</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    max_block <span class="op">=</span> max<span class="op">(</span>max_block<span class="op">,</span> __shfl_down_sync<span class="op">(</span><span class="bn">0xFFFFFFFF</span><span class="op">,</span> max_block<span class="op">,</span> <span class="dv">8</span><span class="op">));</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    max_block <span class="op">=</span> max<span class="op">(</span>max_block<span class="op">,</span> __shfl_down_sync<span class="op">(</span><span class="bn">0xFFFFFFFF</span><span class="op">,</span> max_block<span class="op">,</span> <span class="dv">4</span><span class="op">));</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    max_block <span class="op">=</span> max<span class="op">(</span>max_block<span class="op">,</span> __shfl_down_sync<span class="op">(</span><span class="bn">0xFFFFFFFF</span><span class="op">,</span> max_block<span class="op">,</span> <span class="dv">2</span><span class="op">));</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    max_block <span class="op">=</span> max<span class="op">(</span>max_block<span class="op">,</span> __shfl_down_sync<span class="op">(</span><span class="bn">0xFFFFFFFF</span><span class="op">,</span> max_block<span class="op">,</span> <span class="dv">1</span><span class="op">));</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    max_block_arr<span class="op">[</span>blockIdx<span class="op">.</span>x<span class="op">]</span> <span class="op">=</span> max_block<span class="op">;</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span></code></pre></div>
<p>I replaced a few thousand operations in 1 thread with ~20 operations
across all of them, but compared to the ~1 million random numbers each
thread generates, I don’t expect a measurable difference.<br />
The new time is 31.51ms, to make sure I ran it a couple more times and
got 31.99ms and 31.75ms, So I’ll just consider it statistically
insignificant, nevertheless, it was interesting to learn the proper way
to reduce within a block.</p>
<h3 id="the-secret-time-sink">The Secret Time Sink</h3>
<p>All this time I showed the CUDA timings of the kernels, they only
included the time it took for the GPU to generate all the random numbers
and find the maximum.<br />
As I explained earlier, this is not the full picture.<br />
Running the basic 1 run version in hyperfine I get a time of
<strong>109.7ms</strong>!<br />
Even accounting for not having the warm up(the basic version reports
~40ms for kernel run), where is all this time coming from? Using a tool
called <code>nvprof</code> that comes included with the CUDA compiler, I
can see another 55ms going to <code>cudaEventCreate</code>:</p>
<pre><code>            Type  Time(%)      Time  Name
 GPU activities:  100.00%  41.459ms  rng(int*, int)
      API calls:   46.54%  55.093ms  cudaEventCreate
                   35.03%  41.465ms  cudaDeviceSynchron</code></pre>
<p>At first, it might seem weird that such a basic function takes most
of the time of the program. But in reality, it’s not the function that
takes all that time, it is the initialization of the CUDA runtime, no
matter what CUDA call comes first, it will take a lot of time.<br />
What is the real time that should be measured? The depends on what the
goal of the measurement is, in my case, the goal is simply to get a
smaller number, and I have no control over the initialization overhead,
so I’m taking the kernel time.<br />
Additionally, if I scaled the program to a bigger amount of battles, the
overhead will remain the same size and disappear within the rest of the
runtime.</p>
<h2 id="bigger-gpu-means-lower-time---sub-10-milliseconds">Bigger GPU
Means Lower Time - Sub 10 Milliseconds</h2>
<p>One final benchmark, this time with the added comparison with a
borrowed Desktop RTX 4080:</p>
<table>
<thead>
<tr class="header">
<th>GPU</th>
<th>Average</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>RTX 2070 Mobile Max-Q</td>
<td>31.51ms</td>
</tr>
<tr class="even">
<td>RTX 4080</td>
<td>6.36ms</td>
</tr>
</tbody>
</table>
<p>Sometimes the best optimization is just throwing more money at the
problem.</p>
<h2 id="summary">Summary</h2>
<p>Optimizing code is a lot of fun, and I’m pretty satisfied with the
results I achieved and the things I learned.<br />
The final version of the solutions is available on my <a
href="https://github.com/CattoFace/graveler-sim">GitHub</a> (the CUDA
code is in the cuda directory)</p>
</div>
<footer>
  <a class="footeritem" href="/">
    <svg width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
    <path d="M8.354 1.146a.5.5 0 0 0-.708 0l-6 6A.5.5 0 0 0 1.5 7.5v7a.5.5 0 0 0 .5.5h4.5a.5.5 0 0 0 .5-.5v-4h2v4a.5.5 0 0 0 .5.5H14a.5.5 0 0 0 .5-.5v-7a.5.5 0 0 0-.146-.354L13 5.793V2.5a.5.5 0 0 0-.5-.5h-1a.5.5 0 0 0-.5.5v1.293zM2.5 14V7.707l5.5-5.5 5.5 5.5V14H10v-4a.5.5 0 0 0-.5-.5h-3a.5.5 0 0 0-.5.5v4z"/>
    </svg>
    <span>Home</span>
  </a>
  <a class="footeritem" href="mailto:blog@barrisrael.com">
    <svg width="16" height="16" fill="currentColor" viewBox="0 0 16 16"><path d="M0 4a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v8a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2zm2-1a1 1 0 0 0-1 1v.217l7 4.2 7-4.2V4a1 1 0 0 0-1-1zm13 2.383-4.708 2.825L15 11.105zm-.034 6.876-5.64-3.471L8 9.583l-1.326-.795-5.64 3.47A1 1 0 0 0 2 13h12a1 1 0 0 0 .966-.741M1 11.105l4.708-2.897L1 5.383z"/></svg>
    <span>E-Mail</span>
  </a>
  <a class="footeritem" href="https://github.barrisrael.com">
    <svg width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
    <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 8.01 0 0 0 16 8c0-4.42-3.58-8-8-8"/>
    </svg>
    <span>GitHub</span>
  </a>
  </footer>
</body>
</html>
